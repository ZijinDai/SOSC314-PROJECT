{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZijinDai/SOSC314-PROJECT/blob/main/%23ICE_shooting_data_collection_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp"
      ],
      "metadata": {
        "id": "NgoX1G8fiN77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yt-dlp \"https://www.youtube.com/hashtag/iceshooting\" \\\n",
        "    --skip-download \\\n",
        "    --write-info-json \\\n",
        "    --write-comments \\\n",
        "    --write-auto-subs \\\n",
        "    --sub-lang \"en.*\" \\\n",
        "    --output \"/content/hashtag_data/%(title)s.%(ext)s\""
      ],
      "metadata": {
        "id": "lWYukrJQRG0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install webvtt-py"
      ],
      "metadata": {
        "id": "crmeu4yBL1P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import webvtt\n",
        "\n",
        "def clean_vtt(vtt_path):\n",
        "    if not os.path.exists(vtt_path): return \"\"\n",
        "    try:\n",
        "        vtt = webvtt.read(vtt_path)\n",
        "        lines = []\n",
        "        for line in vtt: lines.extend(line.text.strip().splitlines())\n",
        "        res, prev = [], None\n",
        "        for l in lines:\n",
        "            if l != prev: res.append(l); prev = l\n",
        "        return \"\\n\".join(res)\n",
        "    except: return \"\"\n",
        "\n",
        "video_list = []\n",
        "comment_list = []\n",
        "\n",
        "data_folder = \"/content/hashtag_data\"\n",
        "json_files = glob.glob(os.path.join(data_folder, \"*.info.json\"))\n",
        "\n",
        "for json_path in json_files:\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        meta = json.load(f)\n",
        "\n",
        "    v_id = meta.get('id') # Unique video ID\n",
        "\n",
        "    # 1. Video metadata and subtitles\n",
        "    vtt_files = glob.glob(json_path.replace(\".info.json\", \"*.vtt\"))\n",
        "    transcript = clean_vtt(vtt_files[0]) if vtt_files else \"\"\n",
        "\n",
        "    video_list.append({\n",
        "        \"video_id\": v_id,\n",
        "        \"title\": meta.get('title'),\n",
        "        \"upload_date\": meta.get('upload_date'),\n",
        "        \"channel\": meta.get('channel'),\n",
        "        \"view_count\": meta.get('view_count'),\n",
        "        \"description\": meta.get('description'),\n",
        "        \"transcript\": transcript\n",
        "    })\n",
        "\n",
        "    # 2. Comments\n",
        "    comments = meta.get('comments', [])\n",
        "    for c in comments:\n",
        "        # 1. Extract the original timestamp\n",
        "        raw_ts = c.get('timestamp')\n",
        "\n",
        "        # 2. Convert timestamp to a numeric format, and then to a date format\n",
        "        try:\n",
        "            if raw_ts:\n",
        "                readable_ts = pd.to_datetime(pd.to_numeric(raw_ts), unit='s')\n",
        "            else:\n",
        "                readable_ts = None\n",
        "        except Exception:\n",
        "            readable_ts = None\n",
        "\n",
        "        comment_list.append({\n",
        "            \"video_id\": v_id,\n",
        "            \"author\": c.get('author'),\n",
        "            \"comment_text\": c.get('text'),\n",
        "            \"timestamp\": readable_ts,\n",
        "            \"like_count\": c.get('like_count')\n",
        "        })\n",
        "\n",
        "# --- Save as double sheets using Pandas' ExcelWriter ---\n",
        "output_file = \"ICE_Research_Relational_Data.xlsx\"\n",
        "with pd.ExcelWriter(output_file) as writer:\n",
        "    pd.DataFrame(video_list).to_excel(writer, sheet_name='Video_Summary', index=False)\n",
        "    pd.DataFrame(comment_list).to_excel(writer, sheet_name='Comment_Details', index=False)\n",
        "\n",
        "print(f\"Double sheets completed: {output_file}\")"
      ],
      "metadata": {
        "id": "xYDuzMmhLxRq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Usa36aJ21EZX",
        "outputId": "d7e8e1aa-580c-49a9-a79a-f9666a6ef853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File not found, please check the path: /content/drive/My Drive/SOSC314/ICE Hashtag Data/CNN_Data_cleaned.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define file path\n",
        "file_path = '/content/drive/My Drive/SOSC314/ICE Hashtag Data/CNN_Data_cleaned.xlsx'\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"File not found, please check the path: {file_path}\")\n",
        "else:\n",
        "    print(\"Loading data and processing Comment_Details...\")\n",
        "\n",
        "    # 3. Read Excel file\n",
        "    # Ensure sheet names match exactly: \"Video_Summary\" and \"Comment_Details\"\n",
        "    df_metadata = pd.read_excel(file_path, sheet_name=\"Video_Summary\", dtype={'video_id': str})\n",
        "    df_comments = pd.read_excel(file_path, sheet_name=\"Comment_Details\", dtype={'video_id': str})\n",
        "\n",
        "    # 4. Data Preprocessing (ID Cleaning)\n",
        "    df_metadata['video_id'] = df_metadata['video_id'].str.strip()\n",
        "    df_comments['video_id'] = df_comments['video_id'].str.strip()\n",
        "\n",
        "    # 5. Timestamp Processing (for Comment_Details table)\n",
        "    # Convert to datetime objects and handle potential errors\n",
        "    df_comments['timestamp'] = pd.to_datetime(df_comments['timestamp'], errors='coerce')\n",
        "\n",
        "    # 6. Sorting\n",
        "    # Sort by timestamp from oldest to newest (helpful for chronological analysis)\n",
        "    df_comments = df_comments.sort_values(by='timestamp', ascending=True)\n",
        "\n",
        "    # 7. Core Cleaning Logic (Filtering)\n",
        "    valid_ids = set(df_metadata['video_id'].unique())\n",
        "    df_comments_cleaned = df_comments[df_comments['video_id'].isin(valid_ids)].copy()\n",
        "\n",
        "    # 8. Results Statistics\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Processing successful!\")\n",
        "    print(f\"Valid videos in Summary: {len(valid_ids)}\")\n",
        "    print(f\"Comments retained: {len(df_comments_cleaned)}\")\n",
        "    print(f\"Comments removed: {len(df_comments) - len(df_comments_cleaned)}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # 9. Save the cleaned results\n",
        "    output_path = '/content/drive/My Drive/SOSC314/ICE Hashtag Data/CNN_Comments_Cleaned.xlsx'\n",
        "\n",
        "    # Using specific date_format to ensure Excel renders the timestamp correctly\n",
        "    df_comments_cleaned.to_excel(output_path, index=False, date_format='yyyy-mm-dd hh:mm:ss')\n",
        "    print(f\"Final cleaned data saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive to access your files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define the paths for your cleaned Excel files\n",
        "# Adjust the folder path if your files are in a different directory\n",
        "folder_path = '/content/drive/My Drive/SOSC314/ICE Hashtag Data/'\n",
        "video_input_path = os.path.join(folder_path, 'CNN_Video_cleaned.xlsx')\n",
        "comments_input_path = os.path.join(folder_path, 'CNN_Comments_Cleaned.xlsx')\n",
        "\n",
        "# 3. Define output CSV paths\n",
        "video_output_csv = os.path.join(folder_path, 'CNN_Video_Final.csv')\n",
        "comments_output_csv = os.path.join(folder_path, 'CNN_Comments_Final.csv')\n",
        "\n",
        "def convert_to_csv():\n",
        "    try:\n",
        "        print(\"Reading Excel files...\")\n",
        "\n",
        "        # 4. Load Excel files\n",
        "        # Force video_id as string to prevent scientific notation or data loss\n",
        "        # Since they only have one sheet, we don't need to specify sheet_name (defaults to the first one)\n",
        "        df_video = pd.read_excel(video_input_path, dtype={'video_id': str})\n",
        "        df_comments = pd.read_excel(comments_input_path, dtype={'video_id': str})\n",
        "\n",
        "        # 5. Optional: Ensure timestamp is in datetime format before saving to CSV\n",
        "        if 'timestamp' in df_comments.columns:\n",
        "            df_comments['timestamp'] = pd.to_datetime(df_comments['timestamp'], errors='coerce')\n",
        "\n",
        "        # 6. Save to CSV\n",
        "        # 'utf-8-sig' ensures that Emoji and special characters display correctly in both Excel and Python\n",
        "        df_video.to_csv(video_output_csv, index=False, encoding='utf-8-sig')\n",
        "        df_comments.to_csv(comments_output_csv, index=False, encoding='utf-8-sig')\n",
        "\n",
        "        print(\"-\" * 30)\n",
        "        print(\"Conversion Successful!\")\n",
        "        print(f\"Video Data Saved: {video_output_csv} ({len(df_video)} rows)\")\n",
        "        print(f\"Comments Data Saved: {comments_output_csv} ({len(df_comments)} rows)\")\n",
        "        print(\"-\" * 30)\n",
        "        print(\"You can now use these CSV files for RQ1, RQ2, and RQ3 analysis.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Run the conversion\n",
        "convert_to_csv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX36VPSjCrxj",
        "outputId": "1712c1e7-129f-4321-d6ee-667fca0317fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reading Excel files...\n",
            "------------------------------\n",
            "Conversion Successful!\n",
            "Video Data Saved: /content/drive/My Drive/SOSC314/ICE Hashtag Data/CNN_Video_Final.csv (65 rows)\n",
            "Comments Data Saved: /content/drive/My Drive/SOSC314/ICE Hashtag Data/CNN_Comments_Final.csv (141371 rows)\n",
            "------------------------------\n",
            "You can now use these CSV files for RQ1, RQ2, and RQ3 analysis.\n"
          ]
        }
      ]
    }
  ]
}